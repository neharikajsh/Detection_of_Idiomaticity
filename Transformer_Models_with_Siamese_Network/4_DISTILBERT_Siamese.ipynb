{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8gXdCtnjq1PK","outputId":"7eda4393-f700-4340-e891-b571d9c13af8","executionInfo":{"status":"ok","timestamp":1673201820650,"user_tz":0,"elapsed":1086,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'SemEval_2022_Task2-idiomaticity'...\n","remote: Enumerating objects: 123, done.\u001b[K\n","remote: Counting objects: 100% (123/123), done.\u001b[K\n","remote: Compressing objects: 100% (106/106), done.\u001b[K\n","remote: Total 123 (delta 48), reused 61 (delta 15), pack-reused 0\u001b[K\n","Receiving objects: 100% (123/123), 2.50 MiB | 11.70 MiB/s, done.\n","Resolving deltas: 100% (48/48), done.\n"]}],"source":["!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zR9ljCJSq3om","outputId":"2990496b-3d2d-434c-f85b-dc0ad092721b","executionInfo":{"status":"ok","timestamp":1673201823003,"user_tz":0,"elapsed":2360,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'AStitchInLanguageModels'...\n","remote: Enumerating objects: 1030, done.\u001b[K\n","remote: Counting objects:   5% (1/17)\u001b[K\rremote: Counting objects:  11% (2/17)\u001b[K\rremote: Counting objects:  17% (3/17)\u001b[K\rremote: Counting objects:  23% (4/17)\u001b[K\rremote: Counting objects:  29% (5/17)\u001b[K\rremote: Counting objects:  35% (6/17)\u001b[K\rremote: Counting objects:  41% (7/17)\u001b[K\rremote: Counting objects:  47% (8/17)\u001b[K\rremote: Counting objects:  52% (9/17)\u001b[K\rremote: Counting objects:  58% (10/17)\u001b[K\rremote: Counting objects:  64% (11/17)\u001b[K\rremote: Counting objects:  70% (12/17)\u001b[K\rremote: Counting objects:  76% (13/17)\u001b[K\rremote: Counting objects:  82% (14/17)\u001b[K\rremote: Counting objects:  88% (15/17)\u001b[K\rremote: Counting objects:  94% (16/17)\u001b[K\rremote: Counting objects: 100% (17/17)\u001b[K\rremote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 1030 (delta 11), reused 4 (delta 4), pack-reused 1013\u001b[K\n","Receiving objects: 100% (1030/1030), 79.59 MiB | 59.45 MiB/s, done.\n","Resolving deltas: 100% (394/394), done.\n"]}],"source":["!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1OczNFNq4_7","outputId":"044f9093-9320-4a47-8c0d-7cf9d9e8228a","executionInfo":{"status":"ok","timestamp":1673201832403,"user_tz":0,"elapsed":9406,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","/content\n"]}],"source":["!pip install transformers\n","%cd /content/ "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVN0vrZTq6oX","outputId":"d97c500b-c496-4398-ead1-be6cb623bbd5","executionInfo":{"status":"ok","timestamp":1673201837723,"user_tz":0,"elapsed":5325,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.13 xxhash-3.2.0\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jj_uaj3aq8Od"},"outputs":[],"source":["import site\n","site.main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSUai3g0q-Ji"},"outputs":[],"source":["import os\n","import csv\n","\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jst76TcOq_kX"},"outputs":[],"source":["def load_csv( path, delimiter=',' ) : \n","  header = None\n","  data   = list()\n","  with open( path, encoding='utf-8') as csvfile:\n","    reader = csv.reader( csvfile, delimiter=delimiter ) \n","    for row in reader : \n","      if header is None : \n","        header = row\n","        continue\n","      data.append( row ) \n","  return header, data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6SA-GvKrBSY"},"outputs":[],"source":["def write_csv( data, location ) : \n","  with open( location, 'w', encoding='utf-8') as csvfile:\n","    writer = csv.writer( csvfile ) \n","    writer.writerows( data ) \n","  print( \"Wrote {}\".format( location ) ) \n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHJHosMVVNXS"},"outputs":[],"source":["class Node():\n","  def __init__(self, sentence, label):\n","    self.sentence = sentence\n","    self.label = label\n","\n","def create_idiom_dict_train(data_location, file_name) :\n","    idiom_dict = {}\n","    file_name = os.path.join( data_location, file_name ) \n","    header, data = load_csv( file_name )\n","    for elem in data:\n","        label     = elem[ header.index( 'Label'  ) ]\n","        sentence = elem[ header.index( 'Target' ) ]\n","        idiom = elem[ header.index( 'MWE' ) ]\n","        if idiom in idiom_dict:\n","          idiom_dict[idiom].append(Node(sentence, label))\n","        else:\n","          idiom_dict[idiom] = [Node(sentence, label)]\n","    return idiom_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWO_TnshqY21"},"outputs":[],"source":["d1 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_zero_shot.csv')\n","d2 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_one_shot.csv')\n","for key, value in d2.items():\n","  if key in d1:\n","    d1[key].append(value)\n","  else:\n","    d1[key] = value"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvkkIptrrDsB"},"outputs":[],"source":["def _get_train_data( data_location, file_name, include_context, include_idiom ) :\n","    \n","    file_name = os.path.join( data_location, file_name ) \n","\n","    header, data = load_csv( file_name )\n","\n","    out_header = [ 'label1', 'label2', 'sentence1', 'sentence3' ]\n","    if include_idiom :\n","        out_header = [ 'label1', 'label2', 'sentence1', 'sentence2', 'sentence3', 'sentence4' ]\n","        \n","    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n","    out_data = list()\n","    for elem1 in data :\n","        label     = elem1[ header.index( 'Label'  ) ]\n","        sentence1 = elem1[ header.index( 'Target' ) ]\n","        if include_context :\n","            sentence1 = ' '.join( [ elem1[ header.index( 'Previous' ) ], elem1[ header.index( 'Target' ) ], elem1[ header.index( 'Next' ) ] ] )\n","        for elem2 in d1[elem1[ header.index( 'MWE' ) ]]:\n","          if elem2.sentence != sentence1:\n","              label2     = elem2.label\n","              sentence2 = elem2.sentence\n","              this_row = None\n","              if not include_idiom :\n","                  this_row = [ label, label2, sentence1, sentence2 ] \n","              else :\n","                  sentence3 = elem1[ header.index( 'MWE' ) ]\n","                  sentence4 = sentence3\n","                  this_row = [ label, label2, sentence1, sentence3, sentence2, sentence4]\n","              out_data.append( this_row )\n","              assert len( out_header ) == len( this_row )\n","    return [ out_header ] + out_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rMWvYWX8rGsu"},"outputs":[],"source":["def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n","\n","    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n","    gold_header  = gold_data = None\n","    if not gold_file_name is None : \n","        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n","        assert len( input_data ) == len( gold_data )\n","\n","    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n","    # ['ID', 'DataID', 'Language', 'Label']\n","    \n","    out_header = [ 'label1', 'label2', 'sentence1', 'sentence3' ]\n","    if include_idiom :\n","        out_header = [ 'label1', 'label2', 'label3', 'sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5', 'sentence6', 'language' ]\n","\n","    out_data = list()\n","    for index in range( len( input_data ) ) :\n","        label = 1\n","        if not gold_file_name is None : \n","            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n","            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n","            assert this_input_id == this_gold_id\n","            \n","            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n","            language = gold_data[index][gold_header.index('Language')]\n","        elem      = input_data[ index ]\n","        sentence1 = elem[ input_headers.index( 'Target' ) ]\n","        if include_context :\n","            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n","        this_row = None\n","        if not include_idiom :\n","            this_row = [ label, sentence1 ] \n","        else :\n","            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n","            this_row = [ label, sentence1, sentence2 ]\n","        idiom = elem[ input_headers.index( 'MWE' ) ]\n","        other_nodes = d1[idiom]\n","        if(len(other_nodes)==1):\n","            if not include_idiom :\n","                this_row = [ label, other_nodes[0].label, sentence1, other_nodes[0].sentence ] \n","            else :\n","                sentence2 = elem[ input_headers.index( 'MWE' ) ]\n","                this_row = [ label, other_nodes[0].label, other_nodes[0].label, sentence1, sentence2, other_nodes[0].sentence, sentence2, other_nodes[0].sentence, sentence2, language ]\n","        else:\n","            if not include_idiom :\n","                this_row = [ label, other_nodes[0].label, sentence1, other_nodes[0].sentence ] \n","            else :\n","                sentence2 = elem[ input_headers.index( 'MWE' ) ]\n","                this_row = [ label, other_nodes[0].label, other_nodes[1].label, sentence1, sentence2, other_nodes[0].sentence, sentence2, other_nodes[1].sentence, sentence2, language ]\n","           \n","        assert len( out_header ) == len( this_row ) \n","        out_data.append( this_row )\n","        \n","\n","    return [ out_header ] + out_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4bPrXRRrJ6H"},"outputs":[],"source":["def create_data( input_location, output_location ) :\n","\n","    \n","    ## Zero shot data\n","    train_data = _get_train_data(\n","        data_location   = input_location,\n","        file_name       = 'train_zero_shot.csv',\n","        include_context = True,\n","        include_idiom   = False\n","    )\n","    write_csv( train_data, os.path.join( output_location, 'ZeroShot', 'train.csv' ) )\n","    \n","    dev_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'dev.csv',\n","        gold_file_name   = 'dev_gold.csv', \n","        include_context  = True,\n","        include_idiom    = False\n","    )        \n","    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n","    \n","    eval_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'eval.csv',\n","        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n","        include_context  = True,\n","        include_idiom    = False\n","    )\n","    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n","\n","\n","    ## OneShot Data (combine both for training)\n","    train_zero_data = _get_train_data(\n","        data_location   = input_location,\n","        file_name       = 'train_zero_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","    train_one_data = _get_train_data(\n","        data_location   = input_location,\n","        file_name       = 'train_one_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","\n","    assert train_zero_data[0] == train_one_data[0] ## Headers\n","    train_data = train_one_data + train_zero_data[1:]\n","    write_csv( train_data, os.path.join( output_location, 'OneShot', 'train.csv' ) )\n","    \n","    dev_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'dev.csv',\n","        gold_file_name   = 'dev_gold.csv', \n","        include_context  = False,\n","        include_idiom    = True\n","    )        \n","    write_csv( dev_data, os.path.join( output_location, 'OneShot', 'dev.csv' ) )\n","    \n","    eval_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'eval.csv',\n","        gold_file_name   = None,\n","        include_context  = False,\n","        include_idiom    = True\n","    )\n","    write_csv( eval_data, os.path.join( output_location, 'OneShot', 'eval.csv' ) )\n","\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7t8zqdt9zAQo"},"outputs":[],"source":["train_zero_data = _get_train_data(\n","        data_location   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n","        file_name       = 'train_zero_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","train_one_data = _get_train_data(\n","        data_location   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n","        file_name       = 'train_one_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","\n","assert train_zero_data[0] == train_one_data[0] ## Headers\n","train_data = train_one_data + train_zero_data[1:]\n","\n","dev_data = _get_dev_eval_data(\n","        data_location    = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n","        input_file_name  = 'dev.csv',\n","        gold_file_name   = 'dev_gold.csv', \n","        include_context  = False,\n","        include_idiom    = True\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnJSMleDrO64","outputId":"d19d1081-1334-4447-e690-4adff6a60745","executionInfo":{"status":"ok","timestamp":1673201838231,"user_tz":0,"elapsed":7,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["AStitchInLanguageModels  sample_data  SemEval_2022_Task2-idiomaticity\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AW_HqBIFrPbE"},"outputs":[],"source":["outpath = 'Data'\n","\n","Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n","Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n","\n","# create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"183UBr4ArRSh"},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import random\n","import pickle\n","import logging\n","\n","from typing          import Optional\n","from dataclasses     import dataclass, field\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","from datasets        import load_dataset, load_metric\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModel,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    PretrainedConfig,\n","    Trainer,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n",")\n","from transformers.utils         import check_min_version\n","from transformers.trainer_utils import get_last_checkpoint, is_main_process"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtZiIQ5SrXBd"},"outputs":[],"source":["# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n","check_min_version(\"4.6.0.dev0\")\n","\n","task_to_keys = {\n","    \"cola\": (\"sentence\", None),\n","    \"mnli\": (\"premise\", \"hypothesis\"),\n","    \"mrpc\": (\"sentence1\", \"sentence2\"),\n","    \"qnli\": (\"question\", \"sentence\"),\n","    \"qqp\": (\"question1\", \"question2\"),\n","    \"rte\": (\"sentence1\", \"sentence2\"),\n","    \"sst2\": (\"sentence\", None),\n","    \"stsb\": (\"sentence1\", \"sentence2\"),\n","    \"wnli\": (\"sentence1\", \"sentence2\"),\n","}\n","\n","logger = logging.getLogger(__name__)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0EdhT3XrZCu","outputId":"14a9793e-b25a-4553-f461-29ccc25257ed","executionInfo":{"status":"ok","timestamp":1673201844595,"user_tz":0,"elapsed":22,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['label1', 'label2', 'sentence1', 'sentence2', 'sentence3', 'sentence4'],\n"," ['0',\n","  '1',\n","  'Program leaders said the scholarship defines public service broadly and imagines a variety of pathways toward civic engagement.',\n","  'public service',\n","  'In the ensuing years, Wennberg might not have managed to knock down the parking deck, but his administration helped keep Central Vermont Public Service from moving its corporate headquarters out of the city, and after successfully fighting a number of shopping centers city officials worried would pose a threat to downtown, he negotiated a deal that kept Diamond Run Mall from hosting a movie theater or supermarket and got the city a couple million dollars in payments that funded a variety of projects through the years.',\n","  'public service'],\n"," ['1',\n","  '0',\n","  'In the ensuing years, Wennberg might not have managed to knock down the parking deck, but his administration helped keep Central Vermont Public Service from moving its corporate headquarters out of the city, and after successfully fighting a number of shopping centers city officials worried would pose a threat to downtown, he negotiated a deal that kept Diamond Run Mall from hosting a movie theater or supermarket and got the city a couple million dollars in payments that funded a variety of projects through the years.',\n","  'public service',\n","  'Program leaders said the scholarship defines public service broadly and imagines a variety of pathways toward civic engagement.',\n","  'public service'],\n"," ['0',\n","  '1',\n","  'Blockchains, fundamentally, are banking because what they’re doing is allowing the transaction of value across networks … they’re doing it in an orthogonally different way,\" he said Wednesday in what may be his swan song in public office.',\n","  'swan song',\n","  'They’ve also got:“ Killers of the Flower Moon,” directed by Martin Scorsese and starring Leonardo DiCaprio and Robert De Niro; “Swan Song” with Mahershala Ali, Naomie Harris and Glenn Close and Awkwafina; “Kitbag,” from Ridley Scott and Joaquin Phoenix; A24’s “Sharper” with Julianne Moore; and “Snow Blind” with Jake Gyllenhaal.',\n","  'swan song']]"]},"metadata":{},"execution_count":19}],"source":["train_data[0:4]"]},{"cell_type":"code","source":["dev_data[0:4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmvwVfzQd7sZ","executionInfo":{"status":"ok","timestamp":1673201844596,"user_tz":0,"elapsed":20,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}},"outputId":"103d15cf-582d-4f1d-e13a-06e1e86a95b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['label1',\n","  'label2',\n","  'label3',\n","  'sentence1',\n","  'sentence2',\n","  'sentence3',\n","  'sentence4',\n","  'sentence5',\n","  'sentence6',\n","  'language'],\n"," ['1',\n","  '1',\n","  '1',\n","  'Are these interruptions of the good life a necessary condition of the high life?',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'EN'],\n"," ['1',\n","  '1',\n","  '1',\n","  \"But for Australian fashion designer Abby Kheir, there's no reason not to treat her employees to a taste of the high life all-year round.\",\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'EN'],\n"," ['1',\n","  '1',\n","  '1',\n","  'With that, I will be enjoying the pleasures of the high life knowing I earned money the hard way: Gambling with a bit of mega luck.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'EN']]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QJsCAgjzt-9","executionInfo":{"status":"ok","timestamp":1673201846533,"user_tz":0,"elapsed":1953,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}},"colab":{"base_uri":"https://localhost:8080/","height":201,"referenced_widgets":["87ae8f48ffba47ee955e151e10040f7b","0dfc3fc7487d4fb9967740a8af75e33c","68cdd1963fe74e3199cc9b5e62cd1d18","88e21565ba184be7bb643163bf61838f","d6587582a6274f2ca39f8ff7e74f39aa","2b24d2f8e9f04ac3a3ea64749d73e246","c2b786277abc4cfba3ff17bba00f0599","29421cb99e7f41fd83a36b9a774e05df","436aa2dc394f4ee3a26e83d5e48c9b5a","7e4ccd7d44cc410ea476d15e35404eae","1fa4550f4f2f4485ab9c07a80ad28f0a","39995a7489994026b73f78cac2bb3ec1","d38fa88f65c047438348272655a5d949","b3f3c109b3074588ab07387ed073cd3d","9d78cf1f4caa412db830dece88562c02","2f69c2aadf3e48a1bb77a74bf6afb5e3","653077be6cc74c38b249015e3829f731","5b17d40d208044c490c54990a4dbe28c","77b5b7e0b7bf4d2588710366ccb46a85","f13829fd9fb742399358dfbe3b0df69d","ffa8487fe286421c99c31350055e8268","dce502731950444a9c978d39eb5ddafd","b4f877e9d5cc449ca8875d147ad3269d","34f463e70fa548c3bb74acab57b691ed","8ac01ce95953415d9bfaf4617b257d9b","d7fde93d310d486c8a29f8b4f188f9ab","d0f02d1eafbc43ac8a63dd8c114569b3","996f8b868a2540b1afb1615c107ce13c","81bba1412a4c46e7b355edef470fcf9b","b299953e62fd40ecafb3a26362c52b13","cb163c75b3b84b678281b57e649abb08","9d2fb13381c94994a6fb7fe085aea946","e63974588bb94c39852ac9fed05c8aaf","c66e0d6bfea045a3854e9c61ad159174","e1afa064485e48c8ad34beeae8b91927","6271fdf335694762ae525888a820469d","d8f573d221bd443c8d405053eb57b1c4","39eb623c855b4ac7913fc4c4257767c3","6e1de8b79b8d44c187ff9c8be84406c4","b662820b68cd43c7b9a897289f223d06","c72f403da1f64d80b4b246ecbb60f134","0b9ade073c824eebbe4f39db5f7b3ffe","85b995c6cee04fab8559c806bf423683","2965f8864db14454a747ab1ea8b04688"]},"outputId":"b73101ff-a524-43b0-e4b8-8a4974b6dbf9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ae8f48ffba47ee955e151e10040f7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/466 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39995a7489994026b73f78cac2bb3ec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4f877e9d5cc449ca8875d147ad3269d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c66e0d6bfea045a3854e9c61ad159174"}},"metadata":{}}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","from keras_preprocessing.sequence import pad_sequences\n","import torch\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('distilbert-base-multilingual-cased',\n","                                          cache_dir=None,\n","                                          use_fast=True,\n","                                          revision=\"main\",\n","                                          use_auth_token=None,)"]},{"cell_type":"code","source":["def shuffle_data(data):\n","    indices = list(range(len(data)))\n","    random.shuffle(indices)\n","    shuffled_data = []\n","    for i in indices:\n","        shuffled_data.append(data[i])\n","    return shuffled_data"],"metadata":{"id":"rxajbXyYtpJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUGKP2VK0PY6"},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","def Preprocess_Data(input, tokenizer, max_len, batch_size, data_class=\"train\"):\n","    input1 = []\n","    input2 = []\n","    label1 = []\n","    label2 = []\n","    for i in input:\n","      \"\"\"if(i[1]!='1' and i[1]!='0'):\n","        continue\"\"\"\n","      label1.append(int(i[0]))\n","      label2.append(int(i[1]))\n","      args = (\n","            (i[2], i[3])\n","      )\n","      input1.append(args)\n","      args = (\n","            (i[4], i[5])\n","      )\n","      input2.append(args)\n","    encoded_input1 = tokenizer(input1, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    encoded_input2 = tokenizer(input2, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    \n","    input_ids1 = encoded_input1['input_ids']\n","    attention_mask1 = encoded_input1['attention_mask']\n","    labels1 = torch.tensor(label1)\n","\n","    #print(input_ids1.size(), attention_mask1.size(), labels1.size())\n","\n","    input_ids2 = encoded_input2['input_ids']\n","    attention_mask2 = encoded_input2['attention_mask']\n","    labels2 = torch.tensor(label2)\n","\n","    #print(input_ids2.size(), attention_mask2.size(), labels2.size())\n","    dataset_tensor = TensorDataset(input_ids1, attention_mask1, labels1, input_ids2, attention_mask2, labels2)\n","\n","    if data_class == \"train\":\n","        sampler = RandomSampler(dataset_tensor)\n","    else:\n","        sampler = SequentialSampler(dataset_tensor)\n","    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n","\n","    return dataloader\n","#train_dataloader = preproces(train_data[1:], tokenizer, max_len, batch_size, data_class=\"train\")\n","#dev_dataloader = preproces(eval_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")\n","#test_dataloader = preproces(dev_Data[1:], tokenizer, max_len, batch_size, data_class=\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uIP79MjDtx5r"},"outputs":[],"source":["max_len = 512\n","batch_size = 32\n","def PreProcess_Dev(input, tokenizer, max_len, batch_size, data_class=\"dev\"):\n","    input1 = []\n","    input2 = []\n","    input3 = []\n","    label1 = []\n","    label2 = []\n","    label3 = []\n","    language = []\n","    for i in input:\n","      \"\"\"if(i[1]!='1' and i[1]!='0'):\n","        continue\"\"\"\n","      label1.append(int(i[0]))\n","      label2.append(int(i[1]))\n","      label3.append(int(i[2]))\n","      args = (\n","            (i[3], i[4])\n","      )\n","      input1.append(args)\n","      args = (\n","            (i[5], i[6])\n","      )\n","      input2.append(args)\n","      args = (\n","          (i[7], i[8])\n","      )\n","      input3.append(args)\n","      if i[9]=='EN':\n","        language.append(0)\n","      else:\n","        language.append(1)\n","    encoded_input1 = tokenizer(input1, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    encoded_input2 = tokenizer(input2, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    encoded_input3 = tokenizer(input3, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    input_ids1 = encoded_input1['input_ids']\n","    attention_mask1 = encoded_input1['attention_mask']\n","    labels1 = torch.tensor(label1)\n","    print(input_ids1.size(), attention_mask1.size(), labels1.size())\n","\n","    input_ids2 = encoded_input2['input_ids']\n","    attention_mask2 = encoded_input2['attention_mask']\n","    labels2 = torch.tensor(label2)\n","\n","    print(input_ids2.size(), attention_mask2.size(), labels2.size())\n","\n","    input_ids3 = encoded_input3['input_ids']\n","    attention_mask3 = encoded_input3['attention_mask']\n","    labels3 = torch.tensor(label3)\n","\n","    print(input_ids3.size(), attention_mask3.size(), labels3.size())  \n","    language = torch.tensor(language)  \n","\n","    dataset_tensor = TensorDataset(input_ids1, attention_mask1, labels1, input_ids2, attention_mask2, labels2, input_ids3, attention_mask3, labels3, language)\n","\n","    if data_class == \"train\":\n","        sampler = RandomSampler(dataset_tensor)\n","    else:\n","        sampler = SequentialSampler(dataset_tensor)\n","    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n","\n","    return dataloader\n","#dev_dataloader = preproces_dev(dev_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GoS9OP9e0IcN"},"outputs":[],"source":["import torch.nn as nn\n","class SiameseModel(nn.Module):\n","    def __init__(self):\n","        super(SiameseModel, self).__init__()\n","        \n","        self.base_model = AutoModel.from_pretrained(\n","            'distilbert-base-multilingual-cased',\n","            from_tf=bool(\".ckpt\" in 'distilbert-base-multilingual-cased'),\n","            config=config,\n","            cache_dir=None,\n","            revision=\"main\",\n","            use_auth_token=None,\n","        ).cuda()\n","        self.dropout = nn.Dropout(0.5)\n","        self.linear = nn.Linear(768, 2).cuda() # output features from bert is 768 and 2 is ur number of labels\n","        \n","    def forward(self, input_ids1, attn_mask1, input_ids2, attn_mask2):\n","        #outputs1 = self.base_model(input_ids1, attention_mask=attn_mask1)[1]\n","        #outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2)[1]\n","        outputs1 = self.base_model(input_ids1, attention_mask=attn_mask1).last_hidden_state[:, 0]\n","        outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2).last_hidden_state[:, 0]\n","        difference = outputs1*outputs2\n","        # You write you new head here\n","        outputs = self.dropout(difference)\n","        outputs = self.linear(outputs)\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05DDBBjOYzrs"},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score\n","def Eval(bert_model, dataloader):\n","\n","    bert_model.eval()\n","    predictions, true_labels = [], []\n","    predictions_en, true_labels_en = [], []\n","    predictions_pt, true_labels_pt = [], []\n","    num_correct = 0\n","    \n","    for step, batch in enumerate(tqdm(dataloader)):\n","        batch = tuple(t.to(device) for t in batch)\n","        with torch.no_grad():\n","            logits1 = nn.functional.softmax(bert_model.forward(batch[0], batch[1], batch[3], batch[4]), -1)\n","        with torch.no_grad():\n","            logits2 = nn.functional.softmax(bert_model.forward(batch[0], batch[1], batch[6], batch[7]), -1)\n","        logits = torch.cat((logits1, logits2), dim=1)\n","        max_args = torch.argmax(logits, dim=1)\n","        batch_predictions = []\n","        batch_true_labels = batch[2]\n","        first_sentence_labels = batch[5]\n","        second_sentence_labels = batch[8]\n","        batch_en_predictions = []\n","        batch_pt_predictions = []\n","        true_en_predictions = []\n","        true_pt_predictions = []\n","        language = batch[9]\n","        for idx, instance in enumerate(max_args):\n","          if instance == 0:\n","            batch_predictions.append((first_sentence_labels[idx] - 1) * -1) # 0, 1 toggle\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append((first_sentence_labels[idx] - 1) * -1)\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append((first_sentence_labels[idx] - 1) * -1)\n","              true_pt_predictions.append(batch_true_labels[idx])\n","          elif instance == 1:\n","            batch_predictions.append(first_sentence_labels[idx])\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append(first_sentence_labels[idx])\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append(first_sentence_labels[idx])\n","              true_pt_predictions.append(batch_true_labels[idx])\n","          elif instance == 2:\n","            batch_predictions.append((second_sentence_labels[idx] - 1) * -1)\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append((second_sentence_labels[idx] - 1) * -1)\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append((second_sentence_labels[idx] - 1) * -1)\n","              true_pt_predictions.append(batch_true_labels[idx])\n","          else:\n","            batch_predictions.append(second_sentence_labels[idx])\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append(second_sentence_labels[idx])\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append(second_sentence_labels[idx])\n","              true_pt_predictions.append(batch_true_labels[idx])\n","        predictions += batch_predictions\n","        true_labels += batch_true_labels\n","        predictions_en += batch_en_predictions\n","        predictions_pt += batch_pt_predictions\n","        true_labels_en += true_en_predictions\n","        true_labels_pt += true_pt_predictions\n","    return true_labels, predictions, true_labels_en, predictions_en, true_labels_pt, predictions_pt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jYDcfd5eY2oR"},"outputs":[],"source":["def metrics(true_labels, predictions):\n","    pre = []\n","    tl = []\n","    num_correct = 0\n","    for pred, true_label in zip(predictions, true_labels):\n","        pre.append(int(pred.item()))\n","        tl.append(int(true_label.item()))\n","        if pred == true_label:\n","            num_correct += 1\n","    print(\"\\nAccuracy: %s\" % (float(num_correct) / float(len(true_labels))))\n","    print(\"F1 Score \")\n","    print(f1_score(tl, pre, average='macro'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"np7YcOhL4IWQ"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def Train_Eval(bert_model, train_data, lr, n_epoch, tokenizer, batch_size, max_len):\n","\n","    print(\"Start Training!\")\n","    optimizer = AdamW(bert_model.parameters(), lr=lr)\n","    bert_model.train()\n","    dev_dataloader = PreProcess_Dev(dev_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")\n","    # TRAIN loop\n","    for epoch in range(n_epoch):\n","        shuffled_train_data = shuffle_data(train_data)\n","        shuffled_train_data = Preprocess_Data(shuffled_train_data, tokenizer, max_len, batch_size)\n","        print(f\"\\nEpoch {epoch}\")\n","        torch.cuda.empty_cache()\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","        for step, batch in enumerate(tqdm(shuffled_train_data)):\n","            batch = tuple(t.to(device) for t in batch)\n","            bert_model.zero_grad()\n","            # forward pass\n","            logits = bert_model.forward(batch[0], batch[1], batch[3], batch[4])\n","            # print(loss)\n","            loss = 0\n","            target = torch.where(batch[2]==batch[5], 1, 0)\n","            #target = target.reshape(-1,1)\n","            loss = nn.functional.cross_entropy(logits, target)\n","            \n","            # backward pass\n","            loss.backward()\n","            # track train loss\n","            tr_loss += loss.item()\n","            nb_tr_steps += 1\n","            #loss = loss.detach()\n","            # update parameters\n","            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            \n","\n","        # print train loss per epoch\n","        print(\"Train loss on epoch {}: {}\\n\".format(epoch, tr_loss / nb_tr_steps))\n","\n","    true_labels, predictions, true_labels_en, predictions_en, true_labels_pt, predictions_pt  = Eval(bert_model, dev_dataloader)\n","    print(\"EN-PT\")\n","    metrics(true_labels, predictions)\n","    print(\"EN\")\n","    metrics(true_labels_en, predictions_en)\n","    print(\"PT\")\n","    metrics(true_labels_pt, predictions_pt)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAKW6e6m5IHy","executionInfo":{"status":"ok","timestamp":1673201846814,"user_tz":0,"elapsed":18,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}},"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["3d9ce0e09d6447f6a3b8730873308d75","9d76cb8d05ff47e9b88cdcdf15991585","4e75e935c8354bdbb250f829debaac6d","919b1b19b0024581917f8abeb801812d","6ceae29f5a4b4abfb81386307cecf35c","b45a04c1888c47488f3c1ea18470f41e","63687e75d3264499ace0a1c8c08549d2","37134fe2637142fb8486d51cf76dda55","b25ee98a73454a6889b627ed83edd61d","93fb84e0d7cf4669a707c678e397711b","329e7e18d01c46c7a2d6a4a6ad2a3059"]},"outputId":"aa0a47bc-3ea4-4f7a-d8c6-6c305da68c93"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d9ce0e09d6447f6a3b8730873308d75"}},"metadata":{}}],"source":["config = AutoConfig.from_pretrained(\n","        'bert-base-multilingual-cased',\n","        num_labels=2,\n","        finetuning_task=None,\n","        cache_dir=None,\n","        revision=\"main\",\n","        use_auth_token=None,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":826,"referenced_widgets":["087cf102c12740d2aeca35ae5af24e45","118de907649d4d2da7fdda11f5764687","64c7e149ca9046fd9d6b4211a548c0e7","b2841645d6e74aa69727fed6c790faf0","3a44ac5b209e4dd7988ce55bc413cd61","11d927dfad7d4d5bad1982eb08598670","d24717b13cdd4aa2b688b9f470d86146","d8feff5657ef421691d5d255e8bae36d","5a114146bd834a118d824afedc2271ee","ae303b27a42d4846bc5647c47f378c23","57e4dc21e2e04570b7e37562b1f6fe09"]},"id":"ar64c-jf4rp-","outputId":"74acdd62-4977-4714-e47d-0c341f12f7d1","executionInfo":{"status":"ok","timestamp":1673204340703,"user_tz":0,"elapsed":2493905,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/542M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"087cf102c12740d2aeca35ae5af24e45"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing BertModel: ['vocab_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'vocab_transform.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'vocab_projector.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.weight', 'pooler.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.attention.output.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Start Training!\n","torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n","torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n","torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1347/1347 [13:37<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss on epoch 0: 0.2664451314783584\n","\n","\n","Epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1347/1347 [13:33<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss on epoch 1: 0.013898375512804016\n","\n","\n","Epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1347/1347 [13:34<00:00,  1.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss on epoch 2: 0.0037171122317354102\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 12/12 [00:04<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["EN-PT\n","\n","Accuracy: 0.7104194857916103\n","F1 Score \n","0.7042186611604873\n","EN\n","\n","Accuracy: 0.6652360515021459\n","F1 Score \n","0.6253787644548885\n","PT\n","\n","Accuracy: 0.7875457875457875\n","F1 Score \n","0.7816120489904005\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["model = SiameseModel()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","\n","learning_rate = 2e-5\n","num_epoch = 3                          \n","torch.cuda.empty_cache()\n","max_len = 128\n","batch_size = 64\n","\n","if n_gpu > 1:\n","    model.to(device)\n","    model = torch.nn.DataParallel(model)\n","else:\n","    model.cuda()\n","\n","Train_Eval(model, train_data[1:], learning_rate, num_epoch, tokenizer, batch_size, max_len)\n"]},{"cell_type":"code","source":["# %%shell\n","# jupyter nbconvert --to html 4_DISTILBERT_Siamese.ipynb"],"metadata":{"id":"4yGLjh7vweN_","executionInfo":{"status":"ok","timestamp":1673204465079,"user_tz":0,"elapsed":1276,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}},"outputId":"36348674-5f67-4138-e2fc-3c9588537663","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook 4_DISTILBERT_Siamese.ipynb to html\n","[NbConvertApp] Writing 477446 bytes to 4_DISTILBERT_Siamese.html\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":32}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"87ae8f48ffba47ee955e151e10040f7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dfc3fc7487d4fb9967740a8af75e33c","IPY_MODEL_68cdd1963fe74e3199cc9b5e62cd1d18","IPY_MODEL_88e21565ba184be7bb643163bf61838f"],"layout":"IPY_MODEL_d6587582a6274f2ca39f8ff7e74f39aa"}},"0dfc3fc7487d4fb9967740a8af75e33c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b24d2f8e9f04ac3a3ea64749d73e246","placeholder":"​","style":"IPY_MODEL_c2b786277abc4cfba3ff17bba00f0599","value":"Downloading: 100%"}},"68cdd1963fe74e3199cc9b5e62cd1d18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_29421cb99e7f41fd83a36b9a774e05df","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_436aa2dc394f4ee3a26e83d5e48c9b5a","value":29}},"88e21565ba184be7bb643163bf61838f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e4ccd7d44cc410ea476d15e35404eae","placeholder":"​","style":"IPY_MODEL_1fa4550f4f2f4485ab9c07a80ad28f0a","value":" 29.0/29.0 [00:00&lt;00:00, 1.54kB/s]"}},"d6587582a6274f2ca39f8ff7e74f39aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b24d2f8e9f04ac3a3ea64749d73e246":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2b786277abc4cfba3ff17bba00f0599":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29421cb99e7f41fd83a36b9a774e05df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"436aa2dc394f4ee3a26e83d5e48c9b5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7e4ccd7d44cc410ea476d15e35404eae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa4550f4f2f4485ab9c07a80ad28f0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39995a7489994026b73f78cac2bb3ec1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d38fa88f65c047438348272655a5d949","IPY_MODEL_b3f3c109b3074588ab07387ed073cd3d","IPY_MODEL_9d78cf1f4caa412db830dece88562c02"],"layout":"IPY_MODEL_2f69c2aadf3e48a1bb77a74bf6afb5e3"}},"d38fa88f65c047438348272655a5d949":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_653077be6cc74c38b249015e3829f731","placeholder":"​","style":"IPY_MODEL_5b17d40d208044c490c54990a4dbe28c","value":"Downloading: 100%"}},"b3f3c109b3074588ab07387ed073cd3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77b5b7e0b7bf4d2588710366ccb46a85","max":466,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f13829fd9fb742399358dfbe3b0df69d","value":466}},"9d78cf1f4caa412db830dece88562c02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffa8487fe286421c99c31350055e8268","placeholder":"​","style":"IPY_MODEL_dce502731950444a9c978d39eb5ddafd","value":" 466/466 [00:00&lt;00:00, 35.5kB/s]"}},"2f69c2aadf3e48a1bb77a74bf6afb5e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"653077be6cc74c38b249015e3829f731":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b17d40d208044c490c54990a4dbe28c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77b5b7e0b7bf4d2588710366ccb46a85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f13829fd9fb742399358dfbe3b0df69d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffa8487fe286421c99c31350055e8268":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dce502731950444a9c978d39eb5ddafd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4f877e9d5cc449ca8875d147ad3269d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34f463e70fa548c3bb74acab57b691ed","IPY_MODEL_8ac01ce95953415d9bfaf4617b257d9b","IPY_MODEL_d7fde93d310d486c8a29f8b4f188f9ab"],"layout":"IPY_MODEL_d0f02d1eafbc43ac8a63dd8c114569b3"}},"34f463e70fa548c3bb74acab57b691ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_996f8b868a2540b1afb1615c107ce13c","placeholder":"​","style":"IPY_MODEL_81bba1412a4c46e7b355edef470fcf9b","value":"Downloading: 100%"}},"8ac01ce95953415d9bfaf4617b257d9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b299953e62fd40ecafb3a26362c52b13","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb163c75b3b84b678281b57e649abb08","value":995526}},"d7fde93d310d486c8a29f8b4f188f9ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d2fb13381c94994a6fb7fe085aea946","placeholder":"​","style":"IPY_MODEL_e63974588bb94c39852ac9fed05c8aaf","value":" 996k/996k [00:00&lt;00:00, 1.91MB/s]"}},"d0f02d1eafbc43ac8a63dd8c114569b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"996f8b868a2540b1afb1615c107ce13c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81bba1412a4c46e7b355edef470fcf9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b299953e62fd40ecafb3a26362c52b13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb163c75b3b84b678281b57e649abb08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d2fb13381c94994a6fb7fe085aea946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e63974588bb94c39852ac9fed05c8aaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c66e0d6bfea045a3854e9c61ad159174":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1afa064485e48c8ad34beeae8b91927","IPY_MODEL_6271fdf335694762ae525888a820469d","IPY_MODEL_d8f573d221bd443c8d405053eb57b1c4"],"layout":"IPY_MODEL_39eb623c855b4ac7913fc4c4257767c3"}},"e1afa064485e48c8ad34beeae8b91927":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e1de8b79b8d44c187ff9c8be84406c4","placeholder":"​","style":"IPY_MODEL_b662820b68cd43c7b9a897289f223d06","value":"Downloading: 100%"}},"6271fdf335694762ae525888a820469d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c72f403da1f64d80b4b246ecbb60f134","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b9ade073c824eebbe4f39db5f7b3ffe","value":1961828}},"d8f573d221bd443c8d405053eb57b1c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85b995c6cee04fab8559c806bf423683","placeholder":"​","style":"IPY_MODEL_2965f8864db14454a747ab1ea8b04688","value":" 1.96M/1.96M [00:00&lt;00:00, 1.80MB/s]"}},"39eb623c855b4ac7913fc4c4257767c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e1de8b79b8d44c187ff9c8be84406c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b662820b68cd43c7b9a897289f223d06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c72f403da1f64d80b4b246ecbb60f134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b9ade073c824eebbe4f39db5f7b3ffe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85b995c6cee04fab8559c806bf423683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2965f8864db14454a747ab1ea8b04688":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d9ce0e09d6447f6a3b8730873308d75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d76cb8d05ff47e9b88cdcdf15991585","IPY_MODEL_4e75e935c8354bdbb250f829debaac6d","IPY_MODEL_919b1b19b0024581917f8abeb801812d"],"layout":"IPY_MODEL_6ceae29f5a4b4abfb81386307cecf35c"}},"9d76cb8d05ff47e9b88cdcdf15991585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b45a04c1888c47488f3c1ea18470f41e","placeholder":"​","style":"IPY_MODEL_63687e75d3264499ace0a1c8c08549d2","value":"Downloading: 100%"}},"4e75e935c8354bdbb250f829debaac6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37134fe2637142fb8486d51cf76dda55","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b25ee98a73454a6889b627ed83edd61d","value":625}},"919b1b19b0024581917f8abeb801812d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_93fb84e0d7cf4669a707c678e397711b","placeholder":"​","style":"IPY_MODEL_329e7e18d01c46c7a2d6a4a6ad2a3059","value":" 625/625 [00:00&lt;00:00, 50.3kB/s]"}},"6ceae29f5a4b4abfb81386307cecf35c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45a04c1888c47488f3c1ea18470f41e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63687e75d3264499ace0a1c8c08549d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37134fe2637142fb8486d51cf76dda55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b25ee98a73454a6889b627ed83edd61d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93fb84e0d7cf4669a707c678e397711b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"329e7e18d01c46c7a2d6a4a6ad2a3059":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"087cf102c12740d2aeca35ae5af24e45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_118de907649d4d2da7fdda11f5764687","IPY_MODEL_64c7e149ca9046fd9d6b4211a548c0e7","IPY_MODEL_b2841645d6e74aa69727fed6c790faf0"],"layout":"IPY_MODEL_3a44ac5b209e4dd7988ce55bc413cd61"}},"118de907649d4d2da7fdda11f5764687":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11d927dfad7d4d5bad1982eb08598670","placeholder":"​","style":"IPY_MODEL_d24717b13cdd4aa2b688b9f470d86146","value":"Downloading: 100%"}},"64c7e149ca9046fd9d6b4211a548c0e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8feff5657ef421691d5d255e8bae36d","max":541808922,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a114146bd834a118d824afedc2271ee","value":541808922}},"b2841645d6e74aa69727fed6c790faf0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae303b27a42d4846bc5647c47f378c23","placeholder":"​","style":"IPY_MODEL_57e4dc21e2e04570b7e37562b1f6fe09","value":" 542M/542M [00:07&lt;00:00, 75.9MB/s]"}},"3a44ac5b209e4dd7988ce55bc413cd61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11d927dfad7d4d5bad1982eb08598670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d24717b13cdd4aa2b688b9f470d86146":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8feff5657ef421691d5d255e8bae36d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a114146bd834a118d824afedc2271ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae303b27a42d4846bc5647c47f378c23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e4dc21e2e04570b7e37562b1f6fe09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}