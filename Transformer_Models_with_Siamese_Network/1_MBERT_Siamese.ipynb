{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8gXdCtnjq1PK","outputId":"372fcbd4-bee7-4c84-ac8b-1924bd074616","executionInfo":{"status":"ok","timestamp":1673727327628,"user_tz":0,"elapsed":1388,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'SemEval_2022_Task2-idiomaticity'...\n","remote: Enumerating objects: 123, done.\u001b[K\n","remote: Counting objects: 100% (123/123), done.\u001b[K\n","remote: Compressing objects: 100% (106/106), done.\u001b[K\n","remote: Total 123 (delta 48), reused 61 (delta 15), pack-reused 0\u001b[K\n","Receiving objects: 100% (123/123), 2.50 MiB | 8.43 MiB/s, done.\n","Resolving deltas: 100% (48/48), done.\n"]}],"source":["!git clone https://github.com/H-TayyarMadabushi/SemEval_2022_Task2-idiomaticity.git"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zR9ljCJSq3om","outputId":"198ea21b-ee88-4810-cc4c-acfc3c85a0c2","executionInfo":{"status":"ok","timestamp":1673727334760,"user_tz":0,"elapsed":7160,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'AStitchInLanguageModels'...\n","remote: Enumerating objects: 1030, done.\u001b[K\n","remote: Counting objects: 100% (17/17), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 1030 (delta 11), reused 4 (delta 4), pack-reused 1013\u001b[K\n","Receiving objects: 100% (1030/1030), 79.59 MiB | 17.53 MiB/s, done.\n","Resolving deltas: 100% (394/394), done.\n"]}],"source":["!git clone https://github.com/H-TayyarMadabushi/AStitchInLanguageModels.git"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1OczNFNq4_7","outputId":"4ab7fc6c-bab3-450d-e9f2-13d862d79a53","executionInfo":{"status":"ok","timestamp":1673727345940,"user_tz":0,"elapsed":11208,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n","/content\n"]}],"source":["!pip install transformers\n","%cd /content/ "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVN0vrZTq6oX","outputId":"2b28fc45-beb1-448b-c93a-d58c54ebddfc","executionInfo":{"status":"ok","timestamp":1673727354303,"user_tz":0,"elapsed":8367,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jj_uaj3aq8Od","executionInfo":{"status":"ok","timestamp":1673727354304,"user_tz":0,"elapsed":13,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["import site\n","site.main()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gSUai3g0q-Ji","executionInfo":{"status":"ok","timestamp":1673727354305,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["import os\n","import csv\n","\n","from pathlib import Path"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jst76TcOq_kX","executionInfo":{"status":"ok","timestamp":1673727354305,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["def load_csv( path, delimiter=',' ) : \n","  header = None\n","  data   = list()\n","  with open( path, encoding='utf-8') as csvfile:\n","    reader = csv.reader( csvfile, delimiter=delimiter ) \n","    for row in reader : \n","      if header is None : \n","        header = row\n","        continue\n","      data.append( row ) \n","  return header, data"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"P6SA-GvKrBSY","executionInfo":{"status":"ok","timestamp":1673727354306,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["def write_csv( data, location ) : \n","  with open( location, 'w', encoding='utf-8') as csvfile:\n","    writer = csv.writer( csvfile ) \n","    writer.writerows( data ) \n","  print( \"Wrote {}\".format( location ) ) \n","  return"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KHJHosMVVNXS","executionInfo":{"status":"ok","timestamp":1673727354306,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["class Node():\n","  def __init__(self, sentence, label):\n","    self.sentence = sentence\n","    self.label = label\n","\n","def create_idiom_dict_train(data_location, file_name) :\n","    idiom_dict = {}\n","    file_name = os.path.join( data_location, file_name ) \n","    header, data = load_csv( file_name )\n","    for elem in data:\n","        label     = elem[ header.index( 'Label'  ) ]\n","        sentence = elem[ header.index( 'Target' ) ]\n","        idiom = elem[ header.index( 'MWE' ) ]\n","        if idiom in idiom_dict:\n","          idiom_dict[idiom].append(Node(sentence, label))\n","        else:\n","          idiom_dict[idiom] = [Node(sentence, label)]\n","    return idiom_dict"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"xWO_TnshqY21","executionInfo":{"status":"ok","timestamp":1673727354307,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["d1 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_zero_shot.csv')\n","d2 = create_idiom_dict_train('SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', 'train_one_shot.csv')\n","for key, value in d2.items():\n","  if key in d1:\n","    d1[key].append(value)\n","  else:\n","    d1[key] = value"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"JvkkIptrrDsB","executionInfo":{"status":"ok","timestamp":1673727354307,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["def _get_train_data( data_location, file_name, include_context, include_idiom ) :\n","    \n","    file_name = os.path.join( data_location, file_name ) \n","\n","    header, data = load_csv( file_name )\n","\n","    out_header = [ 'label1', 'label2', 'sentence1', 'sentence3' ]\n","    if include_idiom :\n","        out_header = [ 'label1', 'label2', 'sentence1', 'sentence2', 'sentence3', 'sentence4' ]\n","        \n","    # ['DataID', 'Language', 'MWE', 'Setting', 'Previous', 'Target', 'Next', 'Label']\n","    out_data = list()\n","    for elem1 in data :\n","        label     = elem1[ header.index( 'Label'  ) ]\n","        sentence1 = elem1[ header.index( 'Target' ) ]\n","        if include_context :\n","            sentence1 = ' '.join( [ elem1[ header.index( 'Previous' ) ], elem1[ header.index( 'Target' ) ], elem1[ header.index( 'Next' ) ] ] )\n","        for elem2 in d1[elem1[ header.index( 'MWE' ) ]]:\n","          if elem2.sentence != sentence1:\n","              label2     = elem2.label\n","              sentence2 = elem2.sentence\n","              this_row = None\n","              if not include_idiom :\n","                  this_row = [ label, label2, sentence1, sentence2 ] \n","              else :\n","                  sentence3 = elem1[ header.index( 'MWE' ) ]\n","                  sentence4 = sentence3\n","                  this_row = [ label, label2, sentence1, sentence3, sentence2, sentence4]\n","              out_data.append( this_row )\n","              assert len( out_header ) == len( this_row )\n","    return [ out_header ] + out_data"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"rMWvYWX8rGsu","executionInfo":{"status":"ok","timestamp":1673727354308,"user_tz":0,"elapsed":13,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["def _get_dev_eval_data( data_location, input_file_name, gold_file_name, include_context, include_idiom ) :\n","\n","    input_headers, input_data = load_csv( os.path.join( data_location, input_file_name ) )\n","    gold_header  = gold_data = None\n","    if not gold_file_name is None : \n","        gold_header  , gold_data  = load_csv( os.path.join( data_location, gold_file_name  ) )\n","        assert len( input_data ) == len( gold_data )\n","\n","    # ['ID', 'Language', 'MWE', 'Previous', 'Target', 'Next']\n","    # ['ID', 'DataID', 'Language', 'Label']\n","    \n","    out_header = [ 'label1', 'label2', 'sentence1', 'sentence3' ]\n","    if include_idiom :\n","        out_header = [ 'label1', 'label2', 'label3', 'sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5', 'sentence6', 'language' ]\n","\n","    out_data = list()\n","    for index in range( len( input_data ) ) :\n","        label = 1\n","        if not gold_file_name is None : \n","            this_input_id = input_data[ index ][ input_headers.index( 'ID' ) ]\n","            this_gold_id  = gold_data [ index ][ gold_header  .index( 'ID' ) ]\n","            assert this_input_id == this_gold_id\n","            \n","            label     = gold_data[ index ][ gold_header.index( 'Label'  ) ]\n","            language = gold_data[index][gold_header.index('Language')]\n","        elem      = input_data[ index ]\n","        sentence1 = elem[ input_headers.index( 'Target' ) ]\n","        if include_context :\n","            sentence1 = ' '.join( [ elem[ input_headers.index( 'Previous' ) ], elem[ input_headers.index( 'Target' ) ], elem[ input_headers.index( 'Next' ) ] ] )\n","        this_row = None\n","        if not include_idiom :\n","            this_row = [ label, sentence1 ] \n","        else :\n","            sentence2 = elem[ input_headers.index( 'MWE' ) ]\n","            this_row = [ label, sentence1, sentence2 ]\n","        idiom = elem[ input_headers.index( 'MWE' ) ]\n","        other_nodes = d1[idiom]\n","        if(len(other_nodes)==1):\n","            if not include_idiom :\n","                this_row = [ label, other_nodes[0].label, sentence1, other_nodes[0].sentence ] \n","            else :\n","                sentence2 = elem[ input_headers.index( 'MWE' ) ]\n","                this_row = [ label, other_nodes[0].label, other_nodes[0].label, sentence1, sentence2, other_nodes[0].sentence, sentence2, other_nodes[0].sentence, sentence2, language ]\n","        else:\n","            if not include_idiom :\n","                this_row = [ label, other_nodes[0].label, sentence1, other_nodes[0].sentence ] \n","            else :\n","                sentence2 = elem[ input_headers.index( 'MWE' ) ]\n","                this_row = [ label, other_nodes[0].label, other_nodes[1].label, sentence1, sentence2, other_nodes[0].sentence, sentence2, other_nodes[1].sentence, sentence2, language ]\n","           \n","        assert len( out_header ) == len( this_row ) \n","        out_data.append( this_row )\n","        \n","\n","    return [ out_header ] + out_data"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"U4bPrXRRrJ6H","executionInfo":{"status":"ok","timestamp":1673727354308,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["def create_data( input_location, output_location ) :\n","\n","    \n","    ## Zero shot data\n","    train_data = _get_train_data(\n","        data_location   = input_location,\n","        file_name       = 'train_zero_shot.csv',\n","        include_context = True,\n","        include_idiom   = False\n","    )\n","    write_csv( train_data, os.path.join( output_location, 'ZeroShot', 'train.csv' ) )\n","    \n","    dev_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'dev.csv',\n","        gold_file_name   = 'dev_gold.csv', \n","        include_context  = True,\n","        include_idiom    = False\n","    )        \n","    write_csv( dev_data, os.path.join( output_location, 'ZeroShot', 'dev.csv' ) )\n","    \n","    eval_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'eval.csv',\n","        gold_file_name   = None , ## Don't have gold evaluation file -- submit to CodaLab\n","        include_context  = True,\n","        include_idiom    = False\n","    )\n","    write_csv( eval_data, os.path.join( output_location, 'ZeroShot', 'eval.csv' ) )\n","\n","\n","    ## OneShot Data (combine both for training)\n","    train_zero_data = _get_train_data(\n","        data_location   = input_location,\n","        file_name       = 'train_zero_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","    train_one_data = _get_train_data(\n","        data_location   = input_location,\n","        file_name       = 'train_one_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","\n","    assert train_zero_data[0] == train_one_data[0] ## Headers\n","    train_data = train_one_data + train_zero_data[1:]\n","    write_csv( train_data, os.path.join( output_location, 'OneShot', 'train.csv' ) )\n","    \n","    dev_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'dev.csv',\n","        gold_file_name   = 'dev_gold.csv', \n","        include_context  = False,\n","        include_idiom    = True\n","    )        \n","    write_csv( dev_data, os.path.join( output_location, 'OneShot', 'dev.csv' ) )\n","    \n","    eval_data = _get_dev_eval_data(\n","        data_location    = input_location,\n","        input_file_name  = 'eval.csv',\n","        gold_file_name   = None,\n","        include_context  = False,\n","        include_idiom    = True\n","    )\n","    write_csv( eval_data, os.path.join( output_location, 'OneShot', 'eval.csv' ) )\n","\n","    return"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"7t8zqdt9zAQo","executionInfo":{"status":"ok","timestamp":1673727354779,"user_tz":0,"elapsed":483,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["train_zero_data = _get_train_data(\n","        data_location   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n","        file_name       = 'train_zero_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","train_one_data = _get_train_data(\n","        data_location   = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n","        file_name       = 'train_one_shot.csv',\n","        include_context = False,\n","        include_idiom   = True\n","    )\n","\n","assert train_zero_data[0] == train_one_data[0] ## Headers\n","train_data = train_one_data + train_zero_data[1:]\n","\n","dev_data = _get_dev_eval_data(\n","        data_location    = 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/',\n","        input_file_name  = 'dev.csv',\n","        gold_file_name   = 'dev_gold.csv', \n","        include_context  = False,\n","        include_idiom    = True\n","    )"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnJSMleDrO64","outputId":"7a5085a0-5a5b-490f-ec30-9c1c8610670f","executionInfo":{"status":"ok","timestamp":1673727354780,"user_tz":0,"elapsed":7,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["AStitchInLanguageModels  sample_data  SemEval_2022_Task2-idiomaticity\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"AW_HqBIFrPbE","executionInfo":{"status":"ok","timestamp":1673727354780,"user_tz":0,"elapsed":4,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["outpath = 'Data'\n","\n","Path( os.path.join( outpath, 'ZeroShot' ) ).mkdir(parents=True, exist_ok=True)\n","Path( os.path.join( outpath, 'OneShot' ) ).mkdir(parents=True, exist_ok=True)\n","\n","# create_data( 'SemEval_2022_Task2-idiomaticity/SubTaskA/Data/', outpath )"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"183UBr4ArRSh","executionInfo":{"status":"ok","timestamp":1673727362470,"user_tz":0,"elapsed":7693,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import random\n","import pickle\n","import logging\n","\n","from typing          import Optional\n","from dataclasses     import dataclass, field\n","from sklearn.metrics import f1_score, accuracy_score\n","\n","from datasets        import load_dataset, load_metric\n","\n","import transformers\n","from transformers import (\n","    AutoConfig,\n","    AutoModel,\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    DataCollatorWithPadding,\n","    EvalPrediction,\n","    HfArgumentParser,\n","    PretrainedConfig,\n","    Trainer,\n","    TrainingArguments,\n","    default_data_collator,\n","    set_seed,\n",")\n","from transformers.utils         import check_min_version\n","from transformers.trainer_utils import get_last_checkpoint, is_main_process"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"qtZiIQ5SrXBd","executionInfo":{"status":"ok","timestamp":1673727362471,"user_tz":0,"elapsed":15,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n","check_min_version(\"4.6.0.dev0\")\n","\n","task_to_keys = {\n","    \"cola\": (\"sentence\", None),\n","    \"mnli\": (\"premise\", \"hypothesis\"),\n","    \"mrpc\": (\"sentence1\", \"sentence2\"),\n","    \"qnli\": (\"question\", \"sentence\"),\n","    \"qqp\": (\"question1\", \"question2\"),\n","    \"rte\": (\"sentence1\", \"sentence2\"),\n","    \"sst2\": (\"sentence\", None),\n","    \"stsb\": (\"sentence1\", \"sentence2\"),\n","    \"wnli\": (\"sentence1\", \"sentence2\"),\n","}\n","\n","logger = logging.getLogger(__name__)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0EdhT3XrZCu","outputId":"e201bdc7-6a26-4f24-ce80-66b0e6933195","executionInfo":{"status":"ok","timestamp":1673727362471,"user_tz":0,"elapsed":13,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['label1', 'label2', 'sentence1', 'sentence2', 'sentence3', 'sentence4'],\n"," ['0',\n","  '1',\n","  'Program leaders said the scholarship defines public service broadly and imagines a variety of pathways toward civic engagement.',\n","  'public service',\n","  'In the ensuing years, Wennberg might not have managed to knock down the parking deck, but his administration helped keep Central Vermont Public Service from moving its corporate headquarters out of the city, and after successfully fighting a number of shopping centers city officials worried would pose a threat to downtown, he negotiated a deal that kept Diamond Run Mall from hosting a movie theater or supermarket and got the city a couple million dollars in payments that funded a variety of projects through the years.',\n","  'public service'],\n"," ['1',\n","  '0',\n","  'In the ensuing years, Wennberg might not have managed to knock down the parking deck, but his administration helped keep Central Vermont Public Service from moving its corporate headquarters out of the city, and after successfully fighting a number of shopping centers city officials worried would pose a threat to downtown, he negotiated a deal that kept Diamond Run Mall from hosting a movie theater or supermarket and got the city a couple million dollars in payments that funded a variety of projects through the years.',\n","  'public service',\n","  'Program leaders said the scholarship defines public service broadly and imagines a variety of pathways toward civic engagement.',\n","  'public service'],\n"," ['0',\n","  '1',\n","  'Blockchains, fundamentally, are banking because what they’re doing is allowing the transaction of value across networks … they’re doing it in an orthogonally different way,\" he said Wednesday in what may be his swan song in public office.',\n","  'swan song',\n","  'They’ve also got:“ Killers of the Flower Moon,” directed by Martin Scorsese and starring Leonardo DiCaprio and Robert De Niro; “Swan Song” with Mahershala Ali, Naomie Harris and Glenn Close and Awkwafina; “Kitbag,” from Ridley Scott and Joaquin Phoenix; A24’s “Sharper” with Julianne Moore; and “Snow Blind” with Jake Gyllenhaal.',\n","  'swan song']]"]},"metadata":{},"execution_count":19}],"source":["train_data[0:4]"]},{"cell_type":"code","source":["dev_data[0:4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmvwVfzQd7sZ","executionInfo":{"status":"ok","timestamp":1673727362472,"user_tz":0,"elapsed":12,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}},"outputId":"d300378b-b696-4397-9cce-bbe2231b055f"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['label1',\n","  'label2',\n","  'label3',\n","  'sentence1',\n","  'sentence2',\n","  'sentence3',\n","  'sentence4',\n","  'sentence5',\n","  'sentence6',\n","  'language'],\n"," ['1',\n","  '1',\n","  '1',\n","  'Are these interruptions of the good life a necessary condition of the high life?',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'EN'],\n"," ['1',\n","  '1',\n","  '1',\n","  \"But for Australian fashion designer Abby Kheir, there's no reason not to treat her employees to a taste of the high life all-year round.\",\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'EN'],\n"," ['1',\n","  '1',\n","  '1',\n","  'With that, I will be enjoying the pleasures of the high life knowing I earned money the hard way: Gambling with a bit of mega luck.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'Despite having the riches to afford the high life, PSG captain Marquinhos is still in touch with his past life before becoming a multi-millionaire footballer.',\n","  'high life',\n","  'EN']]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","execution_count":21,"metadata":{"id":"0QJsCAgjzt-9","executionInfo":{"status":"ok","timestamp":1673727373009,"user_tz":0,"elapsed":10545,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["cf493571146f4bc584edc208c69e6f4e","3f5da401f6af4cf3b5c4c6120618c9d7","a6bcae5cc4d84fb6a3e4db1605a3283e","71e2c5e3611b479ca681680df33b5baa","9081625df18d4370b23725c0c0492435","ff8fa360298b4dd6905bda7b0c822bbd","462d0a399262443ea8bd8ff35ab54e09","14efa912f93d4c16b9d13cd2612d2df2","14e25a7c0af64243bdcde31301723af2","261f2d5311ae49a7b8f7bd6fb3dd0c23","f0ec5362450f4880ba3196c90c21ce99","a48fc28b5f9b4c64ae4cbd013f66eb99","b97f7f174e20480192365b0f808c4641","74fb0e9c1ec7471c889b16f36044021c","9229f5fd7be04e6c85cf6cea2c78f65f","84c6ecaa7a9241508822c9e6fe95599f","ed6de083fb6e4c748c8204278a647649","8f5c902146454f43aeffc22739d4f94b","9c620faf5ea644d689ee79f40a838e72","8494855b5024401aa6a4269331a4c37e","40504fd96bf44f6fb0944a103cead73c","dd0f21b44abf450783a7d29e14ae6f95","b6783be4f1c84b01933ab3ec2cb4cbc6","7ded576b1db7400d92a9e03f26ca16f4","89a1cf186f924de2a57abb300d56bcdf","b75308748cd34b229af2ddef92be4ef1","be3a74da2f764d508fc803ea4a3d208b","7827c329362341998c227da3ca937d34","a2b60195e2ec4a53928b98450574865b","06d0922bdb5a452385a88eec903ab8c0","0968172f5ae343b69fd7a2847077efb3","b08beb95c0b84d30bb48d46babdf3af4","abf1c9e6a74c489bbcd8a26426637dfd","b61176196723437ca85e74f38b317a3a","e86c2eb59b4947a6bc90eff82e3c55c7","17d6c48f8fd74d678b076fae7160d620","5b48be6d555f419aa3820278f303ef0f","ccb4f570de254987bb9253e5a39da2e1","838c1a9467ce4d2286b001b5465f2a2f","a6952d16c8344f1798a795be9e3d7d28","ab5550dd9be74d248a7968535bd8cf83","b0e25a711be74e2280cdf9206864a49a","f9ad26a41d674c1293d5d608d6e26353","2236fa10a0af46f6bb43dc9dae457a4e"]},"outputId":"2615bcd3-a762-4ebd-d246-15a752355da8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf493571146f4bc584edc208c69e6f4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a48fc28b5f9b4c64ae4cbd013f66eb99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6783be4f1c84b01933ab3ec2cb4cbc6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61176196723437ca85e74f38b317a3a"}},"metadata":{}}],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n","from keras_preprocessing.sequence import pad_sequences\n","import torch\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased',\n","                                          cache_dir=None,\n","                                          use_fast=True,\n","                                          revision=\"main\",\n","                                          use_auth_token=None,)"]},{"cell_type":"code","source":["def shuffle_data(data):\n","    indices = list(range(len(data)))\n","    random.shuffle(indices)\n","    shuffled_data = []\n","    for i in indices:\n","        shuffled_data.append(data[i])\n","    return shuffled_data"],"metadata":{"id":"rxajbXyYtpJp","executionInfo":{"status":"ok","timestamp":1673727373010,"user_tz":0,"elapsed":9,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","execution_count":23,"metadata":{"id":"nUGKP2VK0PY6","executionInfo":{"status":"ok","timestamp":1673727373684,"user_tz":0,"elapsed":6,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","def Preprocess_Data(input, tokenizer, max_len, batch_size, data_class=\"train\"):\n","    input1 = []\n","    input2 = []\n","    label1 = []\n","    label2 = []\n","    for i in input:\n","      \"\"\"if(i[1]!='1' and i[1]!='0'):\n","        continue\"\"\"\n","      label1.append(int(i[0]))\n","      label2.append(int(i[1]))\n","      args = (\n","            (i[2], i[3])\n","      )\n","      input1.append(args)\n","      args = (\n","            (i[4], i[5])\n","      )\n","      input2.append(args)\n","    encoded_input1 = tokenizer(input1, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    encoded_input2 = tokenizer(input2, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    \n","    input_ids1 = encoded_input1['input_ids']\n","    attention_mask1 = encoded_input1['attention_mask']\n","    labels1 = torch.tensor(label1)\n","\n","    #print(input_ids1.size(), attention_mask1.size(), labels1.size())\n","\n","    input_ids2 = encoded_input2['input_ids']\n","    attention_mask2 = encoded_input2['attention_mask']\n","    labels2 = torch.tensor(label2)\n","\n","    #print(input_ids2.size(), attention_mask2.size(), labels2.size())\n","    dataset_tensor = TensorDataset(input_ids1, attention_mask1, labels1, input_ids2, attention_mask2, labels2)\n","\n","    if data_class == \"train\":\n","        sampler = RandomSampler(dataset_tensor)\n","    else:\n","        sampler = SequentialSampler(dataset_tensor)\n","    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n","\n","    return dataloader\n","#train_dataloader = preproces(train_data[1:], tokenizer, max_len, batch_size, data_class=\"train\")\n","#dev_dataloader = preproces(eval_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")\n","#test_dataloader = preproces(dev_Data[1:], tokenizer, max_len, batch_size, data_class=\"test\")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"uIP79MjDtx5r","executionInfo":{"status":"ok","timestamp":1673727373685,"user_tz":0,"elapsed":6,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["max_len = 512\n","batch_size = 32\n","def PreProcess_Dev(input, tokenizer, max_len, batch_size, data_class=\"dev\"):\n","    input1 = []\n","    input2 = []\n","    input3 = []\n","    label1 = []\n","    label2 = []\n","    label3 = []\n","    language = []\n","    for i in input:\n","      \"\"\"if(i[1]!='1' and i[1]!='0'):\n","        continue\"\"\"\n","      label1.append(int(i[0]))\n","      label2.append(int(i[1]))\n","      label3.append(int(i[2]))\n","      args = (\n","            (i[3], i[4])\n","      )\n","      input1.append(args)\n","      args = (\n","            (i[5], i[6])\n","      )\n","      input2.append(args)\n","      args = (\n","          (i[7], i[8])\n","      )\n","      input3.append(args)\n","      if i[9]=='EN':\n","        language.append(0)\n","      else:\n","        language.append(1)\n","    encoded_input1 = tokenizer(input1, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    encoded_input2 = tokenizer(input2, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    encoded_input3 = tokenizer(input3, padding='max_length', max_length = max_len, truncation=True, return_tensors=\"pt\")\n","    input_ids1 = encoded_input1['input_ids']\n","    attention_mask1 = encoded_input1['attention_mask']\n","    labels1 = torch.tensor(label1)\n","    print(input_ids1.size(), attention_mask1.size(), labels1.size())\n","\n","    input_ids2 = encoded_input2['input_ids']\n","    attention_mask2 = encoded_input2['attention_mask']\n","    labels2 = torch.tensor(label2)\n","\n","    print(input_ids2.size(), attention_mask2.size(), labels2.size())\n","\n","    input_ids3 = encoded_input3['input_ids']\n","    attention_mask3 = encoded_input3['attention_mask']\n","    labels3 = torch.tensor(label3)\n","\n","    print(input_ids3.size(), attention_mask3.size(), labels3.size())  \n","    language = torch.tensor(language)  \n","\n","    dataset_tensor = TensorDataset(input_ids1, attention_mask1, labels1, input_ids2, attention_mask2, labels2, input_ids3, attention_mask3, labels3, language)\n","\n","    if data_class == \"train\":\n","        sampler = RandomSampler(dataset_tensor)\n","    else:\n","        sampler = SequentialSampler(dataset_tensor)\n","    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n","\n","    return dataloader\n","#dev_dataloader = preproces_dev(dev_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"GoS9OP9e0IcN","executionInfo":{"status":"ok","timestamp":1673727373685,"user_tz":0,"elapsed":6,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["import torch.nn as nn\n","class SiameseModel(nn.Module):\n","    def __init__(self):\n","        super(SiameseModel, self).__init__()\n","        \n","        self.base_model = AutoModel.from_pretrained(\n","            'bert-base-multilingual-cased',\n","            from_tf=bool(\".ckpt\" in 'bert-base-multilingual-cased'),\n","            config=config,\n","            cache_dir=None,\n","            revision=\"main\",\n","            use_auth_token=None,\n","        ).cuda()\n","        self.dropout = nn.Dropout(0.5)\n","        self.linear = nn.Linear(768, 2).cuda() # output features from bert is 768 and 2 is ur number of labels\n","        \n","    def forward(self, input_ids1, attn_mask1, input_ids2, attn_mask2):\n","        #outputs1 = self.base_model(input_ids1, attention_mask=attn_mask1)[1]\n","        #outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2)[1]\n","        outputs1 = self.base_model(input_ids1, attention_mask=attn_mask1).last_hidden_state[:, 0]\n","        outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2).last_hidden_state[:, 0]\n","        difference = outputs1*outputs2\n","        # You write you new head here\n","        outputs = self.dropout(difference)\n","        outputs = self.linear(outputs)\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"05DDBBjOYzrs","executionInfo":{"status":"ok","timestamp":1673727373685,"user_tz":0,"elapsed":6,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score\n","def Eval(bert_model, dataloader):\n","\n","    bert_model.eval()\n","    predictions, true_labels = [], []\n","    predictions_en, true_labels_en = [], []\n","    predictions_pt, true_labels_pt = [], []\n","    num_correct = 0\n","    \n","    for step, batch in enumerate(tqdm(dataloader)):\n","        batch = tuple(t.to(device) for t in batch)\n","        with torch.no_grad():\n","            logits1 = nn.functional.softmax(bert_model.forward(batch[0], batch[1], batch[3], batch[4]), -1)\n","        with torch.no_grad():\n","            logits2 = nn.functional.softmax(bert_model.forward(batch[0], batch[1], batch[6], batch[7]), -1)\n","        logits = torch.cat((logits1, logits2), dim=1)\n","        max_args = torch.argmax(logits, dim=1)\n","        batch_predictions = []\n","        batch_true_labels = batch[2]\n","        first_sentence_labels = batch[5]\n","        second_sentence_labels = batch[8]\n","        batch_en_predictions = []\n","        batch_pt_predictions = []\n","        true_en_predictions = []\n","        true_pt_predictions = []\n","        language = batch[9]\n","        for idx, instance in enumerate(max_args):\n","          if instance == 0:\n","            batch_predictions.append((first_sentence_labels[idx] - 1) * -1) # 0, 1 toggle\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append((first_sentence_labels[idx] - 1) * -1)\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append((first_sentence_labels[idx] - 1) * -1)\n","              true_pt_predictions.append(batch_true_labels[idx])\n","          elif instance == 1:\n","            batch_predictions.append(first_sentence_labels[idx])\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append(first_sentence_labels[idx])\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append(first_sentence_labels[idx])\n","              true_pt_predictions.append(batch_true_labels[idx])\n","          elif instance == 2:\n","            batch_predictions.append((second_sentence_labels[idx] - 1) * -1)\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append((second_sentence_labels[idx] - 1) * -1)\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append((second_sentence_labels[idx] - 1) * -1)\n","              true_pt_predictions.append(batch_true_labels[idx])\n","          else:\n","            batch_predictions.append(second_sentence_labels[idx])\n","            if language[idx].item() == 0:\n","              batch_en_predictions.append(second_sentence_labels[idx])\n","              true_en_predictions.append(batch_true_labels[idx])\n","            else:\n","              batch_pt_predictions.append(second_sentence_labels[idx])\n","              true_pt_predictions.append(batch_true_labels[idx])\n","        predictions += batch_predictions\n","        true_labels += batch_true_labels\n","        predictions_en += batch_en_predictions\n","        predictions_pt += batch_pt_predictions\n","        true_labels_en += true_en_predictions\n","        true_labels_pt += true_pt_predictions\n","    return true_labels, predictions, true_labels_en, predictions_en, true_labels_pt, predictions_pt"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"jYDcfd5eY2oR","executionInfo":{"status":"ok","timestamp":1673727373686,"user_tz":0,"elapsed":7,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["def metrics(true_labels, predictions):\n","    pre = []\n","    tl = []\n","    num_correct = 0\n","    for pred, true_label in zip(predictions, true_labels):\n","        pre.append(int(pred.item()))\n","        tl.append(int(true_label.item()))\n","        if pred == true_label:\n","            num_correct += 1\n","    print(\"\\nAccuracy: %s\" % (float(num_correct) / float(len(true_labels))))\n","    print(\"F1 Score \")\n","    print(f1_score(tl, pre, average='macro'))"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"np7YcOhL4IWQ","executionInfo":{"status":"ok","timestamp":1673727373686,"user_tz":0,"elapsed":6,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["from tqdm import tqdm\n","\n","def Train_Eval(bert_model, train_data, lr, n_epoch, tokenizer, batch_size, max_len):\n","\n","    print(\"Start Training!\")\n","    optimizer = AdamW(bert_model.parameters(), lr=lr)\n","    bert_model.train()\n","    dev_dataloader = PreProcess_Dev(dev_data[1:], tokenizer, max_len, batch_size, data_class=\"dev\")\n","    # TRAIN loop\n","    for epoch in range(n_epoch):\n","        shuffled_train_data = shuffle_data(train_data)\n","        shuffled_train_data = Preprocess_Data(shuffled_train_data, tokenizer, max_len, batch_size)\n","        print(f\"\\nEpoch {epoch}\")\n","        torch.cuda.empty_cache()\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","        for step, batch in enumerate(tqdm(shuffled_train_data)):\n","            batch = tuple(t.to(device) for t in batch)\n","            bert_model.zero_grad()\n","            # forward pass\n","            logits = bert_model.forward(batch[0], batch[1], batch[3], batch[4])\n","            # print(loss)\n","            loss = 0\n","            target = torch.where(batch[2]==batch[5], 1, 0)\n","            #target = target.reshape(-1,1)\n","            loss = nn.functional.cross_entropy(logits, target)\n","            \n","            # backward pass\n","            loss.backward()\n","            # track train loss\n","            tr_loss += loss.item()\n","            nb_tr_steps += 1\n","            #loss = loss.detach()\n","            # update parameters\n","            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            \n","\n","        # print train loss per epoch\n","        print(\"Train loss on epoch {}: {}\\n\".format(epoch, tr_loss / nb_tr_steps))\n","\n","    true_labels, predictions, true_labels_en, predictions_en, true_labels_pt, predictions_pt  = Eval(bert_model, dev_dataloader)\n","    print(\"EN-PT\")\n","    metrics(true_labels, predictions)\n","    print(\"EN\")\n","    metrics(true_labels_en, predictions_en)\n","    print(\"PT\")\n","    metrics(true_labels_pt, predictions_pt)\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"oAKW6e6m5IHy","executionInfo":{"status":"ok","timestamp":1673727374050,"user_tz":0,"elapsed":370,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[],"source":["config = AutoConfig.from_pretrained(\n","        'bert-base-multilingual-cased',\n","        num_labels=2,\n","        finetuning_task=None,\n","        cache_dir=None,\n","        revision=\"main\",\n","        use_auth_token=None,\n","    )"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":693,"referenced_widgets":["8b7f581a7ec4470680c61c834c2efc8e","5bad2897c3c0414d9e10b387fd804163","5b1346be90444003bbec4449c5a18dcf","a1588cf4815e4388ab9d0b5c0096c2c4","b5cae61c28bf4314a5755a623bc8a091","12eef8e13fcd40cc8e4f543f10c1be1a","991129a668024989b34f949c0b785715","550d749fdd884674a77677ef9eec9fc3","7d221448ce5243a3bea925fcf067f450","ab32a608736649829d5cd318f9d543c7","ec8d436cedb142b2a288cdf9854fd14f"]},"id":"ar64c-jf4rp-","outputId":"45615de8-d40b-4bac-da69-35ed0c2ff361","executionInfo":{"status":"error","timestamp":1673727415031,"user_tz":0,"elapsed":40984,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b7f581a7ec4470680c61c834c2efc8e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Start Training!\n","torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n","torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n","torch.Size([739, 128]) torch.Size([739, 128]) torch.Size([739])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 0\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 1/1347 [00:06<2:14:48,  6.01s/it]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-5bd7f249ac1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mTrain_Eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-542f9d7fd87b>\u001b[0m in \u001b[0;36mTrain_Eval\u001b[0;34m(bert_model, train_data, lr, n_epoch, tokenizer, batch_size, max_len)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-d79c3389c449>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids1, attn_mask1, input_ids2, attn_mask2)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#outputs2 = self.base_model(input_ids2, attention_mask=attn_mask2)[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moutputs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutputs2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# You write you new head here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         )\n\u001b[0;32m-> 1021\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    608\u001b[0m                 )\n\u001b[1;32m    609\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    611\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 426\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 14.76 GiB total capacity; 13.88 GiB already allocated; 17.75 MiB free; 13.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["model = SiameseModel()\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","\n","learning_rate = 2e-5\n","num_epoch = 3                          \n","torch.cuda.empty_cache()\n","max_len = 128\n","batch_size = 64\n","\n","if n_gpu > 1:\n","    model.to(device)\n","    model = torch.nn.DataParallel(model)\n","else:\n","    model.cuda()\n","\n","Train_Eval(model, train_data[1:], learning_rate, num_epoch, tokenizer, batch_size, max_len)\n"]},{"cell_type":"code","source":["%%shell\n","jupyter nbconvert --to html 2_MBERT_Siamese.ipynb"],"metadata":{"id":"GX_dxcPXEtvC","executionInfo":{"status":"aborted","timestamp":1673727415034,"user_tz":0,"elapsed":22,"user":{"displayName":"Neharika Joshi","userId":"10536822327511302738"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"cf493571146f4bc584edc208c69e6f4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f5da401f6af4cf3b5c4c6120618c9d7","IPY_MODEL_a6bcae5cc4d84fb6a3e4db1605a3283e","IPY_MODEL_71e2c5e3611b479ca681680df33b5baa"],"layout":"IPY_MODEL_9081625df18d4370b23725c0c0492435"}},"3f5da401f6af4cf3b5c4c6120618c9d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff8fa360298b4dd6905bda7b0c822bbd","placeholder":"​","style":"IPY_MODEL_462d0a399262443ea8bd8ff35ab54e09","value":"Downloading: 100%"}},"a6bcae5cc4d84fb6a3e4db1605a3283e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14efa912f93d4c16b9d13cd2612d2df2","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14e25a7c0af64243bdcde31301723af2","value":29}},"71e2c5e3611b479ca681680df33b5baa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_261f2d5311ae49a7b8f7bd6fb3dd0c23","placeholder":"​","style":"IPY_MODEL_f0ec5362450f4880ba3196c90c21ce99","value":" 29.0/29.0 [00:00&lt;00:00, 1.80kB/s]"}},"9081625df18d4370b23725c0c0492435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff8fa360298b4dd6905bda7b0c822bbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462d0a399262443ea8bd8ff35ab54e09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14efa912f93d4c16b9d13cd2612d2df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14e25a7c0af64243bdcde31301723af2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"261f2d5311ae49a7b8f7bd6fb3dd0c23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ec5362450f4880ba3196c90c21ce99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a48fc28b5f9b4c64ae4cbd013f66eb99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b97f7f174e20480192365b0f808c4641","IPY_MODEL_74fb0e9c1ec7471c889b16f36044021c","IPY_MODEL_9229f5fd7be04e6c85cf6cea2c78f65f"],"layout":"IPY_MODEL_84c6ecaa7a9241508822c9e6fe95599f"}},"b97f7f174e20480192365b0f808c4641":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed6de083fb6e4c748c8204278a647649","placeholder":"​","style":"IPY_MODEL_8f5c902146454f43aeffc22739d4f94b","value":"Downloading: 100%"}},"74fb0e9c1ec7471c889b16f36044021c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c620faf5ea644d689ee79f40a838e72","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8494855b5024401aa6a4269331a4c37e","value":625}},"9229f5fd7be04e6c85cf6cea2c78f65f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40504fd96bf44f6fb0944a103cead73c","placeholder":"​","style":"IPY_MODEL_dd0f21b44abf450783a7d29e14ae6f95","value":" 625/625 [00:00&lt;00:00, 42.7kB/s]"}},"84c6ecaa7a9241508822c9e6fe95599f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed6de083fb6e4c748c8204278a647649":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f5c902146454f43aeffc22739d4f94b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c620faf5ea644d689ee79f40a838e72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8494855b5024401aa6a4269331a4c37e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40504fd96bf44f6fb0944a103cead73c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd0f21b44abf450783a7d29e14ae6f95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6783be4f1c84b01933ab3ec2cb4cbc6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ded576b1db7400d92a9e03f26ca16f4","IPY_MODEL_89a1cf186f924de2a57abb300d56bcdf","IPY_MODEL_b75308748cd34b229af2ddef92be4ef1"],"layout":"IPY_MODEL_be3a74da2f764d508fc803ea4a3d208b"}},"7ded576b1db7400d92a9e03f26ca16f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7827c329362341998c227da3ca937d34","placeholder":"​","style":"IPY_MODEL_a2b60195e2ec4a53928b98450574865b","value":"Downloading: 100%"}},"89a1cf186f924de2a57abb300d56bcdf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06d0922bdb5a452385a88eec903ab8c0","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0968172f5ae343b69fd7a2847077efb3","value":995526}},"b75308748cd34b229af2ddef92be4ef1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b08beb95c0b84d30bb48d46babdf3af4","placeholder":"​","style":"IPY_MODEL_abf1c9e6a74c489bbcd8a26426637dfd","value":" 996k/996k [00:01&lt;00:00, 1.07MB/s]"}},"be3a74da2f764d508fc803ea4a3d208b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7827c329362341998c227da3ca937d34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b60195e2ec4a53928b98450574865b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06d0922bdb5a452385a88eec903ab8c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0968172f5ae343b69fd7a2847077efb3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b08beb95c0b84d30bb48d46babdf3af4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abf1c9e6a74c489bbcd8a26426637dfd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b61176196723437ca85e74f38b317a3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e86c2eb59b4947a6bc90eff82e3c55c7","IPY_MODEL_17d6c48f8fd74d678b076fae7160d620","IPY_MODEL_5b48be6d555f419aa3820278f303ef0f"],"layout":"IPY_MODEL_ccb4f570de254987bb9253e5a39da2e1"}},"e86c2eb59b4947a6bc90eff82e3c55c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_838c1a9467ce4d2286b001b5465f2a2f","placeholder":"​","style":"IPY_MODEL_a6952d16c8344f1798a795be9e3d7d28","value":"Downloading: 100%"}},"17d6c48f8fd74d678b076fae7160d620":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab5550dd9be74d248a7968535bd8cf83","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0e25a711be74e2280cdf9206864a49a","value":1961828}},"5b48be6d555f419aa3820278f303ef0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9ad26a41d674c1293d5d608d6e26353","placeholder":"​","style":"IPY_MODEL_2236fa10a0af46f6bb43dc9dae457a4e","value":" 1.96M/1.96M [00:01&lt;00:00, 1.92MB/s]"}},"ccb4f570de254987bb9253e5a39da2e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"838c1a9467ce4d2286b001b5465f2a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6952d16c8344f1798a795be9e3d7d28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab5550dd9be74d248a7968535bd8cf83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0e25a711be74e2280cdf9206864a49a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9ad26a41d674c1293d5d608d6e26353":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2236fa10a0af46f6bb43dc9dae457a4e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b7f581a7ec4470680c61c834c2efc8e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bad2897c3c0414d9e10b387fd804163","IPY_MODEL_5b1346be90444003bbec4449c5a18dcf","IPY_MODEL_a1588cf4815e4388ab9d0b5c0096c2c4"],"layout":"IPY_MODEL_b5cae61c28bf4314a5755a623bc8a091"}},"5bad2897c3c0414d9e10b387fd804163":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12eef8e13fcd40cc8e4f543f10c1be1a","placeholder":"​","style":"IPY_MODEL_991129a668024989b34f949c0b785715","value":"Downloading: 100%"}},"5b1346be90444003bbec4449c5a18dcf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_550d749fdd884674a77677ef9eec9fc3","max":714314041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d221448ce5243a3bea925fcf067f450","value":714314041}},"a1588cf4815e4388ab9d0b5c0096c2c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab32a608736649829d5cd318f9d543c7","placeholder":"​","style":"IPY_MODEL_ec8d436cedb142b2a288cdf9854fd14f","value":" 714M/714M [00:10&lt;00:00, 77.2MB/s]"}},"b5cae61c28bf4314a5755a623bc8a091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12eef8e13fcd40cc8e4f543f10c1be1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"991129a668024989b34f949c0b785715":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"550d749fdd884674a77677ef9eec9fc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d221448ce5243a3bea925fcf067f450":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab32a608736649829d5cd318f9d543c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec8d436cedb142b2a288cdf9854fd14f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}